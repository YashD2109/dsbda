# 1. Import required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# 2. Load the dataset
# Dataset: Boston Housing (you can download 'housing.csv' from Kaggle)
df = pd.read_csv('housing.csv')  # assuming the file is named 'housing.csv'

# Preview data
print("Dataset Preview:\n", df.head())

# 3. Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# 4. Define features (X) and target variable (y)
X = df.drop('MEDV', axis=1)   # MEDV is the target (house price)
y = df['MEDV']

# 5. Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Create and train the Linear Regression Model
model = LinearRegression()
model.fit(X_train, y_train)

# 7. Make predictions
y_pred = model.predict(X_test)

# 8. Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nMean Squared Error (MSE):", mse)
print("R-squared (R2 Score):", r2)

# 9. Plot Actual vs Predicted values
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted House Prices")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # perfect line
plt.show()

# 10. Coefficients and Intercept
print("\nModel Coefficients:\n", pd.Series(model.coef_, index=X.columns))
print("\nModel Intercept:\n", model.intercept_)
